{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mido in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: packaging~=23.1 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from mido) (23.1)\n",
      "Requirement already satisfied: pygame in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: music21 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (7.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (3.5.2)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (2.2.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (8.13.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (1.12)\n",
      "Requirement already satisfied: joblib in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (1.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (1.23.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from music21) (5.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from matplotlib->music21) (4.34.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from scikit-learn==1.3.0) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from scikit-learn==1.3.0) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from scikit-learn==1.3.0) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ktrin\\miniconda3\\envs\\w266\\lib\\site-packages (from scikit-learn==1.3.0) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install mido\n",
    "!pip install pygame\n",
    "!pip install music21\n",
    "!pip install scikit-learn==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful libraries\n",
    "import glob, nltk, joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from music21 import midi\n",
    "from plugins.midi2img import midi2img\n",
    "from plugins.img2midi import img2midi\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load In museGAN dataset for visualization purposes\n",
    "It turned out that the people at museGAN is leveraging midi -> image conversion. The image consisted of bar of a multi track piano roll. From the below image, the horizontal represent time and the vericle represent the instrument used. In this dataset the instrument are layered from bottom to top as piano, strings, guitar, drums, bass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ktrin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the punkt tokenizer from nltk to tokenize the piece caption\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of museGAN\n",
    "## External Data Source\n",
    "For whatever reason, if we wanted to perform GAN modeling, we can leverage conversion of MIDI data to that of the piano roll. Download the data from piano repo in README and start performing the things below. [Convert-MIDI-TO-NP-ARRAY](https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caption Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 20 # 18 + start, end\n",
    "EMBED_DIM = 100 \n",
    "MAX_VOCAB_SIZE = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piece_id</th>\n",
       "      <th>piece_description</th>\n",
       "      <th>piece_arousal</th>\n",
       "      <th>piece_name</th>\n",
       "      <th>midi_file</th>\n",
       "      <th>caption_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>very upbeat</td>\n",
       "      <td>Delighted</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>very upbeat. delighted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I could tell the valence of the example was in...</td>\n",
       "      <td>Valence started out moderately negative and pr...</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>i could tell the valence of the example was in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>For a second I thought this piece was going to...</td>\n",
       "      <td>This piece seemed to have a positive valence t...</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>for a second i thought this piece was going to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bouncy and fun</td>\n",
       "      <td>Kind of sparatic</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>bouncy and fun. kind of sparatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>nice</td>\n",
       "      <td>nice</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>nice. nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>6100</td>\n",
       "      <td>It started off slowly but happy and then built...</td>\n",
       "      <td>Seemed to remain consistent almost like it was...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>it started off slowly but happy and then built...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>6101</td>\n",
       "      <td>This starts off a certain way then changes in ...</td>\n",
       "      <td>This is nostalgic because I recognize this and...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>this starts off a certain way then changes in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>6102</td>\n",
       "      <td>The piece begins slow in tempo and then become...</td>\n",
       "      <td>The beginning rhythm sounds suspenseful, makin...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>the piece begins slow in tempo and then become...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>6103</td>\n",
       "      <td>started slow but picked up.</td>\n",
       "      <td>I feel it stayed the same</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>started slow but picked up. . i feel it stayed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>6104</td>\n",
       "      <td>the music is kind of happy and then starts slo...</td>\n",
       "      <td>this music sounds intense. it doesn't change m...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>the music is kind of happy and then starts slo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      piece_id                                  piece_description  \\\n",
       "0            0                                        very upbeat   \n",
       "1            1  I could tell the valence of the example was in...   \n",
       "2            2  For a second I thought this piece was going to...   \n",
       "3            3                                     Bouncy and fun   \n",
       "4            4                                               nice   \n",
       "...        ...                                                ...   \n",
       "6100      6100  It started off slowly but happy and then built...   \n",
       "6101      6101  This starts off a certain way then changes in ...   \n",
       "6102      6102  The piece begins slow in tempo and then become...   \n",
       "6103      6103                       started slow but picked up.    \n",
       "6104      6104  the music is kind of happy and then starts slo...   \n",
       "\n",
       "                                          piece_arousal  \\\n",
       "0                                             Delighted   \n",
       "1     Valence started out moderately negative and pr...   \n",
       "2     This piece seemed to have a positive valence t...   \n",
       "3                                      Kind of sparatic   \n",
       "4                                                  nice   \n",
       "...                                                 ...   \n",
       "6100  Seemed to remain consistent almost like it was...   \n",
       "6101  This is nostalgic because I recognize this and...   \n",
       "6102  The beginning rhythm sounds suspenseful, makin...   \n",
       "6103                         I feel it stayed the same    \n",
       "6104  this music sounds intense. it doesn't change m...   \n",
       "\n",
       "                   piece_name  \\\n",
       "0     Lurking In The Darkness   \n",
       "1     Lurking In The Darkness   \n",
       "2     Lurking In The Darkness   \n",
       "3     Lurking In The Darkness   \n",
       "4     Lurking In The Darkness   \n",
       "...                       ...   \n",
       "6100         One Winged Angel   \n",
       "6101         One Winged Angel   \n",
       "6102         One Winged Angel   \n",
       "6103         One Winged Angel   \n",
       "6104         One Winged Angel   \n",
       "\n",
       "                                              midi_file  \\\n",
       "0     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "1     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "2     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "3     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "4     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "...                                                 ...   \n",
       "6100  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6101  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6102  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6103  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6104  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "\n",
       "                                           caption_list  \n",
       "0                                very upbeat. delighted  \n",
       "1     i could tell the valence of the example was in...  \n",
       "2     for a second i thought this piece was going to...  \n",
       "3                      bouncy and fun. kind of sparatic  \n",
       "4                                            nice. nice  \n",
       "...                                                 ...  \n",
       "6100  it started off slowly but happy and then built...  \n",
       "6101  this starts off a certain way then changes in ...  \n",
       "6102  the piece begins slow in tempo and then become...  \n",
       "6103  started slow but picked up. . i feel it stayed...  \n",
       "6104  the music is kind of happy and then starts slo...  \n",
       "\n",
       "[6105 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the metadata\n",
    "# create a list of captions that concatenate the piece description and arousal\n",
    "# lower case te caption list\n",
    "midi_meta = pd.read_csv('../data/piano-labelled/labelled_piano_midi_metadata.csv')\n",
    "midi_meta['caption_list'] = midi_meta['piece_description'].str.lower()+ \". \" + midi_meta['piece_arousal'].str.lower()\n",
    "midi_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a4690dfb31412982e8c9a5f719698b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build a vocabulary using sklearn count vectorizer to create a vocab from the most frequent words\n",
    "input_captions = []\n",
    "max_caption_length = -1 \n",
    "\n",
    "for caption in tqdm(midi_meta['caption_list'].values):\n",
    "    tokenized_caption = nltk.word_tokenize(caption, language='english')\n",
    "\n",
    "    if len(tokenized_caption) > max_caption_length:\n",
    "        max_caption_length = len(tokenized_caption)\n",
    "\n",
    "    caption = (' '.join(tokenized_caption)).lower()\n",
    "    input_captions.append(caption)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=MAX_VOCAB_SIZE)\n",
    "vectorizer.fit(input_captions)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "MAX_VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn vocab into a dictionary of words and token id\n",
    "# replace some words with special tokens like start/end/unk\n",
    "# if the caption is too short, pad it with <pad> token\n",
    "id_vocab_dict = {}\n",
    "vocab_id_dict = {}\n",
    "\n",
    "for sid, svocab in enumerate(vocab):\n",
    "    id_vocab_dict[sid] = svocab\n",
    "    vocab_id_dict[svocab] = sid\n",
    "\n",
    "id_vocab_dict[MAX_VOCAB_SIZE] = \"<unk>\"\n",
    "id_vocab_dict[MAX_VOCAB_SIZE + 1] = \"<start>\"\n",
    "id_vocab_dict[MAX_VOCAB_SIZE + 2] = \"<end>\"\n",
    "id_vocab_dict[MAX_VOCAB_SIZE + 3] = \"<pad>\"\n",
    "\n",
    "vocab_id_dict[\"<unk>\"] = MAX_VOCAB_SIZE\n",
    "vocab_id_dict[\"<start>\"] = MAX_VOCAB_SIZE + 1\n",
    "vocab_id_dict[\"<end>\"] = MAX_VOCAB_SIZE + 2\n",
    "vocab_id_dict[\"<pad>\"] = MAX_VOCAB_SIZE + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6105"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization - take the input caption and tokenize it\n",
    "# declare a max sequence length \n",
    "def convert_text_to_data(texts, \n",
    "                         vocab_id_dict, \n",
    "                         max_length=20, \n",
    "                         type=None):\n",
    "    \"\"\"\n",
    "        Function to convert text based data into tokenized data with proper padding\n",
    "    \"\"\"\n",
    "\n",
    "    processed_data = []\n",
    "    for text_num, text in enumerate(texts):\n",
    "        sentence_ids = []\n",
    "\n",
    "        # split the sentence into token\n",
    "        # use the vocab to turn the word token into number\n",
    "        for token in text.split():\n",
    "            if token in vocab_id_dict.keys():\n",
    "                sentence_ids.append(vocab_id_dict[token])\n",
    "            else:\n",
    "                sentence_ids.append(vocab_id_dict[\"<unk>\"])\n",
    "\n",
    "        vocab_size = len(vocab_id_dict.keys())\n",
    "\n",
    "        # for decoder cases:\n",
    "        # input sentence: <start>, [tokenize words from vocab], <end>, padded with <unk>\n",
    "        # ouput sentence has: [tokenize words from vocab], <end>, padded with <unk>\n",
    "        if type == 'input_target':\n",
    "            ids = ([vocab_size - 3] + sentence_ids + [vocab_size - 2] + [vocab_size - 1] * max_length)[:max_length]\n",
    "        elif type == 'output_target':\n",
    "            ids = (sentence_ids + [vocab_size - 2] + [vocab_size - 1] * max_length)[:max_length]\n",
    "        processed_data.append(ids)\n",
    "\n",
    "    return np.array(processed_data)\n",
    "\n",
    "\n",
    "train_target_input_data = convert_text_to_data(input_captions,\n",
    "                                                vocab_id_dict,\n",
    "                                                type='input_target',\n",
    "                                                max_length=MAX_SEQ_LENGTH)\n",
    "len(train_target_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piece_id</th>\n",
       "      <th>piece_description</th>\n",
       "      <th>piece_arousal</th>\n",
       "      <th>piece_name</th>\n",
       "      <th>midi_file</th>\n",
       "      <th>caption_list</th>\n",
       "      <th>tokenized_captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>very upbeat</td>\n",
       "      <td>Delighted</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>very upbeat. delighted</td>\n",
       "      <td>[3452, 3319, 3258, 3451, 762, 3453, 3454, 3454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I could tell the valence of the example was in...</td>\n",
       "      <td>Valence started out moderately negative and pr...</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>i could tell the valence of the example was in...</td>\n",
       "      <td>[3452, 3451, 661, 3025, 3053, 3290, 2095, 3053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>For a second I thought this piece was going to...</td>\n",
       "      <td>This piece seemed to have a positive valence t...</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>for a second i thought this piece was going to...</td>\n",
       "      <td>[3452, 1220, 3451, 2627, 3451, 3078, 3074, 224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bouncy and fun</td>\n",
       "      <td>Kind of sparatic</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>bouncy and fun. kind of sparatic</td>\n",
       "      <td>[3452, 364, 138, 1262, 3451, 1686, 2095, 2820,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>nice</td>\n",
       "      <td>nice</td>\n",
       "      <td>Lurking In The Darkness</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_Lurking In...</td>\n",
       "      <td>nice. nice</td>\n",
       "      <td>[3452, 2044, 3451, 2044, 3453, 3454, 3454, 345...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>6100</td>\n",
       "      <td>It started off slowly but happy and then built...</td>\n",
       "      <td>Seemed to remain consistent almost like it was...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>it started off slowly but happy and then built...</td>\n",
       "      <td>[3452, 1623, 2869, 2096, 2756, 413, 1374, 138,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>6101</td>\n",
       "      <td>This starts off a certain way then changes in ...</td>\n",
       "      <td>This is nostalgic because I recognize this and...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>this starts off a certain way then changes in ...</td>\n",
       "      <td>[3452, 3074, 2872, 2096, 3451, 468, 3366, 3061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>6102</td>\n",
       "      <td>The piece begins slow in tempo and then become...</td>\n",
       "      <td>The beginning rhythm sounds suspenseful, makin...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>the piece begins slow in tempo and then become...</td>\n",
       "      <td>[3452, 3053, 2241, 304, 2751, 1510, 3031, 138,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>6103</td>\n",
       "      <td>started slow but picked up.</td>\n",
       "      <td>I feel it stayed the same</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>started slow but picked up. . i feel it stayed...</td>\n",
       "      <td>[3452, 2869, 2751, 413, 2233, 3451, 3451, 3451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>6104</td>\n",
       "      <td>the music is kind of happy and then starts slo...</td>\n",
       "      <td>this music sounds intense. it doesn't change m...</td>\n",
       "      <td>One Winged Angel</td>\n",
       "      <td>Final Fantasy_PS1_Final Fantasy VII_One Winged...</td>\n",
       "      <td>the music is kind of happy and then starts slo...</td>\n",
       "      <td>[3452, 3053, 1996, 1618, 1686, 2095, 1374, 138...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6105 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      piece_id                                  piece_description  \\\n",
       "0            0                                        very upbeat   \n",
       "1            1  I could tell the valence of the example was in...   \n",
       "2            2  For a second I thought this piece was going to...   \n",
       "3            3                                     Bouncy and fun   \n",
       "4            4                                               nice   \n",
       "...        ...                                                ...   \n",
       "6100      6100  It started off slowly but happy and then built...   \n",
       "6101      6101  This starts off a certain way then changes in ...   \n",
       "6102      6102  The piece begins slow in tempo and then become...   \n",
       "6103      6103                       started slow but picked up.    \n",
       "6104      6104  the music is kind of happy and then starts slo...   \n",
       "\n",
       "                                          piece_arousal  \\\n",
       "0                                             Delighted   \n",
       "1     Valence started out moderately negative and pr...   \n",
       "2     This piece seemed to have a positive valence t...   \n",
       "3                                      Kind of sparatic   \n",
       "4                                                  nice   \n",
       "...                                                 ...   \n",
       "6100  Seemed to remain consistent almost like it was...   \n",
       "6101  This is nostalgic because I recognize this and...   \n",
       "6102  The beginning rhythm sounds suspenseful, makin...   \n",
       "6103                         I feel it stayed the same    \n",
       "6104  this music sounds intense. it doesn't change m...   \n",
       "\n",
       "                   piece_name  \\\n",
       "0     Lurking In The Darkness   \n",
       "1     Lurking In The Darkness   \n",
       "2     Lurking In The Darkness   \n",
       "3     Lurking In The Darkness   \n",
       "4     Lurking In The Darkness   \n",
       "...                       ...   \n",
       "6100         One Winged Angel   \n",
       "6101         One Winged Angel   \n",
       "6102         One Winged Angel   \n",
       "6103         One Winged Angel   \n",
       "6104         One Winged Angel   \n",
       "\n",
       "                                              midi_file  \\\n",
       "0     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "1     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "2     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "3     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "4     Final Fantasy_PS1_Final Fantasy VII_Lurking In...   \n",
       "...                                                 ...   \n",
       "6100  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6101  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6102  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6103  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "6104  Final Fantasy_PS1_Final Fantasy VII_One Winged...   \n",
       "\n",
       "                                           caption_list  \\\n",
       "0                                very upbeat. delighted   \n",
       "1     i could tell the valence of the example was in...   \n",
       "2     for a second i thought this piece was going to...   \n",
       "3                      bouncy and fun. kind of sparatic   \n",
       "4                                            nice. nice   \n",
       "...                                                 ...   \n",
       "6100  it started off slowly but happy and then built...   \n",
       "6101  this starts off a certain way then changes in ...   \n",
       "6102  the piece begins slow in tempo and then become...   \n",
       "6103  started slow but picked up. . i feel it stayed...   \n",
       "6104  the music is kind of happy and then starts slo...   \n",
       "\n",
       "                                     tokenized_captions  \n",
       "0     [3452, 3319, 3258, 3451, 762, 3453, 3454, 3454...  \n",
       "1     [3452, 3451, 661, 3025, 3053, 3290, 2095, 3053...  \n",
       "2     [3452, 1220, 3451, 2627, 3451, 3078, 3074, 224...  \n",
       "3     [3452, 364, 138, 1262, 3451, 1686, 2095, 2820,...  \n",
       "4     [3452, 2044, 3451, 2044, 3453, 3454, 3454, 345...  \n",
       "...                                                 ...  \n",
       "6100  [3452, 1623, 2869, 2096, 2756, 413, 1374, 138,...  \n",
       "6101  [3452, 3074, 2872, 2096, 3451, 468, 3366, 3061...  \n",
       "6102  [3452, 3053, 2241, 304, 2751, 1510, 3031, 138,...  \n",
       "6103  [3452, 2869, 2751, 413, 2233, 3451, 3451, 3451...  \n",
       "6104  [3452, 3053, 1996, 1618, 1686, 2095, 1374, 138...  \n",
       "\n",
       "[6105 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# added the tokenized caption to the metadata\n",
    "midi_meta['tokenized_captions'] = train_target_input_data.tolist()\n",
    "midi_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in music and prepare it in a list of notes\n",
    "midis = []\n",
    "for file in tqdm(glob.glob(\"../data/piano-labelled/midi/*.mid\")):\n",
    "    midis.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert MIDI to image\n",
    "# declare output path\n",
    "output_path = \"../data/piano-labelled/midi_img\"\n",
    "\n",
    "# instantiate a midi2img converter object\n",
    "midi2img_obj = midi2img(output_path)\n",
    "\n",
    "# for each midi file, convert it to image\n",
    "for midi in tqdm(midis):\n",
    "    data, metadata = midi2img_obj.convert_to_image(midi)\n",
    "    for img_key in data.keys():\n",
    "        try:\n",
    "            img_path = output_path+\"/\"+midi.split(\"/\")[-1].replace(\".mid\",f\"_{img_key}.png\")\n",
    "            # print(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            basewidth = 106\n",
    "            hsize = 106\n",
    "            img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "            img.save(img_path)\n",
    "        except:\n",
    "            print(\"Error in converting: \"+img_path)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Construction\n",
    "def access_images(path, metadata, num_images=float(\"inf\")):\n",
    "    \"\"\"\n",
    "        Fetch a defined number of images from a directory\n",
    "        and return their normalized pixels arrays\n",
    "        Inputs:\n",
    "            path: path to the directory containing the images\n",
    "            img_list: list of image names\n",
    "            num_images: number of images to fetch\n",
    "        Output:\n",
    "            image_arr: pixel array of images\n",
    "            img: the original image\n",
    "    \"\"\"\n",
    "    pixels = {}\n",
    "    imgs = []\n",
    "\n",
    "    # construct a dictionary of empty lists with the song name\n",
    "    for piece in tqdm(metadata['piece_name'].unique()):\n",
    "        # if row['piece_name'] not in pixels.keys():\n",
    "        #     pixels[row['piece_name']] = []\n",
    "            \n",
    "        # fetch all images from the directory\n",
    "        i = 0\n",
    "        for file in (glob.glob(f\"{path}/*.png\")):\n",
    "            if i >= num_images:\n",
    "                break\n",
    "            try:\n",
    "                img = Image.open(file, 'r')\n",
    "                img = img.convert('1')\n",
    "                pix = np.array(img.getdata())\n",
    "                pix = pix.astype('float32')\n",
    "                pix /= 255.0\n",
    "                \n",
    "                if piece in file:\n",
    "                    if piece not in pixels.keys():\n",
    "                        pixels[piece] = [pix.reshape(106,106,1)]\n",
    "                    else:\n",
    "                        pixels[piece].append(pix.reshape(106,106,1))\n",
    "                # pixels.append(pix.reshape(106,106,1))\n",
    "                imgs.append(img)\n",
    "            except:\n",
    "                pass\n",
    "            i+=1\n",
    "    return pixels, imgs\n",
    "\n",
    "\n",
    "img_dir = \"../data/piano-labelled/midi_img/midi\"\n",
    "pixels_arr, imgs = access_images(img_dir, midi_meta)\n",
    "np.unique(pixels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pixels_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\UNIXSpace\\Git_Desktop\\Berkeley-MIDS\\Classes\\W210 - Capstone\\w210-capstone-fall2023\\workspace\\museGAN_experiment_v2.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Berkeley-MIDS/Classes/W210%20-%20Capstone/w210-capstone-fall2023/workspace/museGAN_experiment_v2.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sound_image \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpiece_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mimage_array\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m#from_dict(pixels_arr, orient='index').reset_index()\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Berkeley-MIDS/Classes/W210%20-%20Capstone/w210-capstone-fall2023/workspace/museGAN_experiment_v2.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sound_image[\u001b[39m'\u001b[39m\u001b[39mpiece_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pixels_arr\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Berkeley-MIDS/Classes/W210%20-%20Capstone/w210-capstone-fall2023/workspace/museGAN_experiment_v2.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sound_image[\u001b[39m'\u001b[39m\u001b[39mimage_array\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pixels_arr\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/UNIXSpace/Git_Desktop/Berkeley-MIDS/Classes/W210%20-%20Capstone/w210-capstone-fall2023/workspace/museGAN_experiment_v2.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sound_image\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pixels_arr' is not defined"
     ]
    }
   ],
   "source": [
    "sound_image = pd.DataFrame(columns=['piece_name', 'image_array'])#from_dict(pixels_arr, orient='index').reset_index()\n",
    "sound_image['piece_name'] = pixels_arr.keys()\n",
    "sound_image['image_array'] = pixels_arr.values()\n",
    "sound_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with metadata\n",
    "midi_meta = midi_meta.merge(sound_image, on='piece_name', how='left').dropna(subset=['piece_name'])\n",
    "midi_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "for i, row in midi_meta.iterrows():\n",
    "    caption = row['tokenized_captions']\n",
    "    images = row['image_array']\n",
    "    try:\n",
    "        for image in images:\n",
    "            training_set.append((image, caption))\n",
    "    except:\n",
    "        pass\n",
    "training_set,len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as joblib\n",
    "joblib.dump(training_set, '../data/piano-labelled/training_set.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Definition\n",
    "\n",
    "GAN model consists of two part:\n",
    "1. Generator\n",
    "2. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# check to see if tensorflow mount to GPU properly\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_enhanced_generator(latent_dim=100, \n",
    "                               caption_dim=MAX_SEQ_LENGTH, \n",
    "                               vocab_size=len(vocab_id_dict.keys()), \n",
    "                               embed_dim=EMBED_DIM):\n",
    "    \"\"\"Define the generator model\n",
    "        Inputs:\n",
    "            latent_dim: dimension of the latent space\n",
    "        Output:\n",
    "            model: the generator model\n",
    "    \"\"\"\n",
    "    n_nodes = 128 * 53 * 53\n",
    "\n",
    "    # vectorized input layers\n",
    "    input_layer = keras.layers.Input(shape=(latent_dim,), name='input_layer')\n",
    "    \n",
    "    # # vectorized caption input layers\n",
    "    # # apply word embedding to the caption\n",
    "    # caption_input_layer = keras.layers.Input(shape=(caption_dim,), name='caption_input_layer')\n",
    "    # embedding_layer  = keras.layers.Embedding(input_dim=vocab_size,\n",
    "    #                                             output_dim=embed_dim,\n",
    "    #                                             name='caption_embedding_layer')\n",
    "    # embed_caption = embedding_layer(caption_input_layer)\n",
    "\n",
    "    # # source_image_encoding = keras.layers.GlobalAveragePooling2D()(dense4)\n",
    "    # # using LSTM to encode the caption with the input layer\n",
    "    # lstm_layer = keras.layers.LSTM(100, return_sequences=True, return_state=True, name=\"decoder_lstm_layer\")\n",
    "    # decoder_output, decoder_state_h_output, decoder_state_c_output = lstm_layer(embed_caption, initial_state=[input_layer, input_layer])\n",
    "\n",
    "    # apply 1D Global Average Pooling to the output of the dense layer on the caption decoded\n",
    "    # global_average_pooling1d_layer = keras.layers.GlobalAveragePooling1D()(decoder_output)\n",
    "\n",
    "    # Dense Layer 1\n",
    "    dense1 = keras.layers.Dense(n_nodes)(input_layer)\n",
    "    leaky_relu1 = keras.layers.LeakyReLU(alpha=0.2)(dense1)\n",
    "    reshape_layer = keras.layers.Reshape((53, 53, 128))(leaky_relu1)\n",
    "\n",
    "    # Dense Layer 2\n",
    "    dense2 =  keras.layers.Dense(1024)(reshape_layer)\n",
    "\n",
    "    # Conv2DTranspose Layer\n",
    "    conv2d_transpose = keras.layers.Conv2DTranspose(1024, (4, 4), strides=(2, 2), padding='same')(dense2)\n",
    "\n",
    "    # Dense Layer 3\n",
    "    dense3 =  keras.layers.Dense(1024)(conv2d_transpose)\n",
    "    leaky_relu2 = keras.layers.LeakyReLU(alpha=0.2)(dense3)\n",
    "\n",
    "    # Dense Layer 4\n",
    "    dense4 =  keras.layers.Dense(1024)(leaky_relu2)\n",
    "\n",
    "    # Conv2D Layer\n",
    "    conv2d = keras.layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid')(dense4)\n",
    "\n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=input_layer, outputs=conv2d)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_enhanced_discriminator(in_shape = (106,106,1)):\n",
    "    \"\"\"\n",
    "        GAN discriminator model\n",
    "        Inputs:\n",
    "            in_shape: shape of the input image\n",
    "        Output:\n",
    "            model: discriminator model with binary crossentropy loss to denotes if the image is real or fake\n",
    "    \"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = keras.layers.Input(shape=in_shape, name='input_layer')\n",
    "    \n",
    "    # 2D Convlution Layer 1\n",
    "    conv1 = keras.layers.Conv2D(64, (3,3), strides=(2, 2), padding='same')(input_layer)\n",
    "    leaky_relu1 = keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    dropout1 = keras.layers.Dropout(0.5)(leaky_relu1)\n",
    "\n",
    "    # 2D Convlution Layer 2\n",
    "    conv2 = keras.layers.Conv2D(64, (3,3), strides=(2, 2), padding='same')(dropout1)\n",
    "    leaky_relu2 = keras.layers.LeakyReLU(alpha=0.2)(conv2)\n",
    "    dropout2 = keras.layers.Dropout(0.5)(leaky_relu2)\n",
    "\n",
    "    # Flatten Layer\n",
    "    flatten_layer = keras.layers.Flatten()(dropout2)\n",
    "\n",
    "    # Batch Normalization Layer\n",
    "    batch_normalization = keras.layers.BatchNormalization()(flatten_layer)\n",
    "\n",
    "    # Dense Output Disminator Layer\n",
    "    discriminate_layer = keras.layers.Dense(1, activation='sigmoid')(batch_normalization)\n",
    "\n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=input_layer, outputs=discriminate_layer)\n",
    "    \n",
    "    # model compile\n",
    "    opt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_enhanced_miniGAN(g_model, d_model,\n",
    "                             g_model_input_shape=100, \n",
    "                             g_model_caption_input_shape=MAX_SEQ_LENGTH):\n",
    "    \"\"\"\n",
    "        GAN model architecture\n",
    "        Inputs:\n",
    "            g_model: generator model\n",
    "            d_model: discriminator model\n",
    "            g_model_input_shape: shape of the input to the generator model\n",
    "            g_model_caption_input_shape: shape of the input caption to the generator model\n",
    "        Output:\n",
    "            model: GAN model\n",
    "    \"\"\"\n",
    "    # Pause the training of the discriminator\n",
    "    d_model.trainable = False\n",
    "\n",
    "    # Define the input layer for the generator\n",
    "    generator_input = keras.layers.Input(shape=(g_model_input_shape))  # Specify the shape of the generator's input\n",
    "    # caption_input = keras.layers.Input(shape=(g_model_caption_input_shape))  # Specify the shape of the generator's input\n",
    "\n",
    "    # Define the output of the generator\n",
    "    generator_output = g_model(generator_input)\n",
    "\n",
    "    # Define the output of the discriminator\n",
    "    discriminator_output = d_model(generator_output)\n",
    "\n",
    "    # Create the model\n",
    "    model = keras.Model(inputs=generator_input, outputs=discriminator_output)\n",
    "\n",
    "    # Compile the model\n",
    "    opt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 359552)            36314752  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 359552)            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 53, 53, 128)       0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 53, 53, 1024)      132096    \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 106, 106, 1024)   16778240  \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 106, 106, 1024)    1049600   \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 106, 106, 1024)    0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 106, 106, 1024)    1049600   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 106, 106, 1)       50177     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,374,465\n",
      "Trainable params: 55,374,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 106, 106, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 53, 53, 64)        640       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 53, 53, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 53, 53, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 27, 27, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 27, 27, 64)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 27, 27, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 46656)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 46656)            186624    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 46657     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,849\n",
      "Trainable params: 0\n",
      "Non-trainable params: 270,849\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 106, 106, 1)       55374465  \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 1)                 270849    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,645,314\n",
      "Trainable params: 55,374,465\n",
      "Non-trainable params: 270,849\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ktrin\\miniconda3\\envs\\W266\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "g_model = caption_enhanced_generator(latent_dim)\n",
    "d_model = caption_enhanced_discriminator()\n",
    "gan_model = caption_enhanced_miniGAN(g_model, d_model)\n",
    "g_model.summary(), d_model.summary(), gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the generated model\n",
    "keras.utils.plot_model(g_model, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the generated model\n",
    "# keras.utils.plot_model(d_model, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the generated model\n",
    "# keras.utils.plot_model(gan_model, show_shapes=True, dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training data\n",
    "import random\n",
    "random.seed(5634)\n",
    "\n",
    "training_set = joblib.load('../data/piano-labelled/training_set.joblib')\n",
    "training_set = random.sample(training_set, 2048) #5 is the lenth of the sample\n",
    "# images, captions = zip(*training_set)\n",
    "# images = np.array(images)\n",
    "# captions = np.array(captions)\n",
    "# images.shape, captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # slice the image and caption from the dataset\n",
    "    # generate 'real' class labels (1)\n",
    "    images, captions = zip(*dataset)\n",
    "    images = np.array(images)\n",
    "    captions = np.array(captions)\n",
    "    ix = np.random.randint(0, images.shape[0], n_samples)\n",
    "    X_img = images[ix]   \n",
    "    X_cap = captions[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X_img, X_cap, y\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, caption, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate samples and save as a plot and save the model\n",
    "# def summarize_performance(step, g_model, gan_model, latent_dim, x_cap, n_samples=100):\n",
    "# \t# prepare fake examples\n",
    "# \tX, _ = generate_fake_samples(g_model, latent_dim, x_cap, n_samples)\n",
    "#     # save plot\n",
    "# \t# scale from [-1,1] to [0,1]\n",
    "# \tX = (X + 1) / 2.0\n",
    "# \t# plot images\n",
    "# \tfor i in range(100):\n",
    "# \t\t# define subplot\n",
    "# \t\tplt.subplot(10, 10, 1 + i)\n",
    "# \t\t# turn off axis\n",
    "# \t\tplt.axis('off')\n",
    "# \t\t# plot raw pixel data\n",
    "# \t\tplt.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "# \t# save plot to file\n",
    "# \tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
    "# \tplt.savefig(filename1)\n",
    "# \tplt.close()\n",
    "# \t# save the generator model\n",
    "# \tfilename2 = 'model_%04d.h5' % (step+1)\n",
    "# \tg_model.save(filename2)\n",
    "# \t# save the gan model\n",
    "# \tfilename3 = 'gan_model_%04d.h5' % (step+1)\n",
    "# \tgan_model.save(filename3)\n",
    "# \tprint('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=50, n_batch=16):\n",
    "    bat_per_epo = int(len(dataset) / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            # prepare a mini batch of real and fake sample\n",
    "            X_img_real, x_cap_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_img_fake, y_fake = generate_fake_samples(g_model, latent_dim, x_cap_real, half_batch)\n",
    "\n",
    "            # print(X_img_real, X_img_fake)\n",
    "            \n",
    "            # use real caption input to generate a fake image\n",
    "            # train the discriminator on fake images generate from real caption and a set of latent points\n",
    "            X, y = np.vstack((X_img_real, X_img_fake)), np.vstack((y_real, y_fake))        \n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            \n",
    "            # print(\"Discriminator Loss: \", (d_loss, _))\n",
    "            # prepare points in latent space and fetch some real caption input\n",
    "\n",
    "            X_img_real_full, x_cap_real_full, y_real_full = generate_real_samples(dataset, n_batch)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "\n",
    "            # perform full batch training on e2e GAN model \n",
    "            # using the latent point and real caption as input\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "\n",
    "            # test print the image\n",
    "            # X = g_model.predict([X_gan, x_cap_real_full])\n",
    "            # print(np.unique(X))\n",
    "\n",
    "        if (i+1) % 2 == 0:\n",
    "            # summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(g_model, d_model, gan_model, training_set, latent_dim, n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "g_model.save('../models/mini-gan/caption_piano_generator_model.h5')\n",
    "d_model.save('../models/mini-gan/caption_piano_discriminator_model.h5')\n",
    "gan_model.save('../models/mini-gan/caption_piano_gan_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "g_model = keras.models.load_model('../models/mini-gan/caption_piano_generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([\"the tempo slows down, making the valence decrease. the arousal, however, gets more intense because the sound get's louder. it'. the valence is not changing because the piece is static. the arousal is also not changing, because it is static.\"],\n",
       "       dtype=object),\n",
       " array([[3452, 3053, 3031, 2758,  891, 3451, 1846, 3053, 3290,  738, 3451,\n",
       "         3053,  199, 3451, 1467, 3451, 1289, 1970, 1563,  291]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a random row from the metadata to get the caption\n",
    "row = midi_meta.sample(1, random_state=74)\n",
    "\n",
    "# get a random image tokenize caption and actual caption\n",
    "NLP_caption = row['caption_list'].values\n",
    "caption = [np.array(a) for a in row['tokenized_captions'].values]\n",
    "caption = np.array(caption)\n",
    "NLP_caption, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 100),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "\n",
    "# declare a latent space\n",
    "latent_dim = 100\n",
    "latent_points = generate_latent_points(latent_dim, 1)\n",
    "latent_points.shape, #caption.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8),\n",
       " array([[[[0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [3.8861237e-34]],\n",
       " \n",
       "         [[0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00]],\n",
       " \n",
       "         [[0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00],\n",
       "          [0.0000000e+00]]]], dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = g_model\n",
    "X = g_model.predict(latent_points)\n",
    "array = np.array(X.reshape(106,106),dtype = np.uint8)\n",
    "np.unique(array), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "array*=255\n",
    "new_image = Image.fromarray(array,'L')\n",
    "new_image = new_image.save(f'../data/midi_reconstruction/images/captioned_piece_test_no_cap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(X)):\n",
    "#     array = np.array(X[i].reshape(106,106),dtype = np.uint8)\n",
    "#     array*=255\n",
    "#     new_image = Image.fromarray(array,'L')\n",
    "#     new_image = new_image.save(f'../data/midi_reconstruction/images/captioned_piece_g40_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconvert MIDI images to MIDI files\n",
    "image_path = \"../data/midi_reconstruction/images/captioned_piece_test_no_cap.png\"\n",
    "output_path = \"../data/midi_reconstruction\"\n",
    "\n",
    "img2midi_obj = img2midi(image_path, output_path, resolution=0.25)\n",
    "img2midi_obj.convert_to_midi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to cell to play\n",
    "# stop the cell and run sp.stop to stop the music\n",
    "from music21 import midi, converter, instrument, note, chord\n",
    "\n",
    "mf = midi.MidiFile()\n",
    "mf.open(f\"{output_path}/music.mid\")\n",
    "mf.read()\n",
    "mf.close()\n",
    "s = midi.translate.midiFileToStream(mf)\n",
    "sp = midi.realtime.StreamPlayer(s)\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method StreamPlayer.stop of <music21.midi.realtime.StreamPlayer object at 0x00000286182130D0>>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
